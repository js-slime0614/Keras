학습은 훈련데이터 샘플과 그에 상응하는 타깃이 주어졌을 때 손실 함수를 최소하 하는 모델 파라미터의 조합을 찾는 것을 의미합니다.
데이터 샘플과 타깃의 배치를 랜덤하게 뽑고 이 배치에서 손실에 대한 파라미터의 그래디언트를 계산함으로써 학습이 진행됩니다. 네트워크의 파라미터는 그래디언트의 반대방향으로 조금씩(학습률에 의해 정의된 크기만큼) 움직입니다.
전체 학습 과정은 신경망이 미분 가능한 첸서 연산으로 연결되어 있기 때문에 가능합니다. 현재 파라미터와 배치 데이터를 그래디언트 값에 매핑해 주는 그래디언트 함수를 구성하기 위해 미분의 연쇄 법칙을 사용합니다.
이어지는 장에서 자주 보게 될 두가지 핵심 개념은 손실과 옵티마이저 입니다. 이 두 가지는 네트워크에 데이터를 주입하기 전에 정의 되어야 합니다.
손실은 훈련하는 동안 최소화해야할 양이므로 해결하려는 문제의 성공을 측정하는 데 사용합니다.
옵티마이저는 손실에 대한 그래디언트가 파라미터를 업데이트 하는 정확한 방식을 정의합니다. 예를 들어 RMSProp 옵티마이저, 모멘템을 사용한 SGD 등입니다.